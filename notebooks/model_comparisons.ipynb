{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2819f3-4d33-4f1f-80c3-25bba5845a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"c2EJIE\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.3.3/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"c2EJIE\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"c2EJIE\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"4ExgNS\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.3.3/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"4ExgNS\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"4ExgNS\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pyfixest as pf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a0d08-f773-4022-9856-0992c81a3fd5",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "609b96ff-1b41-4017-afb2-957f43313080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from countrycode import countrycode as cc\n",
    "from calendar import monthrange\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96fbdf3e-6cd1-4f81-8fe9-2bdfe927855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data = pd.read_csv(\"../data/GDP_per_capita/worldbank_wdi_gdp_per_capita.csv\")\n",
    "tfp_data = pd.read_csv(\"../data/TFP/AgTFPInternational2021_AG_TFP.csv\", header=2)\n",
    "natural_disasters_data = pd.read_csv(\"../data/natural_disasters/emdat_1960-2024.csv\")\n",
    "disaster_types_to_extract = [\"Wildfire\", \"Drought\", \"Extreme temperature\"]\n",
    "gdp_years = range(1961,2024)\n",
    "tfp_years = range(1962,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d127fc-a803-4755-8f63-f06e89049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_target_data(data, years, year_column_format, country_column, output_var):\n",
    "    formatted_outcome_var = {}\n",
    "    for row in data.iterrows():\n",
    "        row = row[1]\n",
    "        country = row[country_column]\n",
    "        formatted_outcome_var[country] = {}\n",
    "        for year in years:\n",
    "            year_data = float(row[year_column_format.replace(\"year\",str(year))])\n",
    "            last_year_data = float(row[year_column_format.replace(\"year\",str(year-1))])\n",
    "            formatted_outcome_var[country][year] = {}\n",
    "            if np.isnan(year_data) or np.isnan(last_year_data):\n",
    "                formatted_outcome_var[country][year][output_var] = np.NaN\n",
    "            else:\n",
    "                outcome = np.log(float(year_data)) - np.log(float(last_year_data))\n",
    "                formatted_outcome_var[country][year][output_var] = outcome\n",
    "    return formatted_outcome_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec49c962-b346-4e9c-973f-8db011bc0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_climate_vars_to_dataset(dataset, climate_val, prev_climate_val, country, year, climate_var, weights):\n",
    "    dataset[country][year][f\"{climate_var}_{weights}\"] = climate_val\n",
    "    dataset[country][year][f\"{climate_var}_{weights}_2\"] = np.square(climate_val)\n",
    "    dataset[country][year][f\"{climate_var}_{weights}_3\"] = np.power(climate_val,3)\n",
    "    if prev_climate_val != None:\n",
    "        dataset[country][year][f\"fd_{climate_var}_{weights}\"] = climate_val - prev_climate_val\n",
    "        dataset[country][year][f\"fd_{climate_var}_{weights}_2\"] = np.square(climate_val) - np.square(prev_climate_val)\n",
    "        dataset[country][year][f\"fd_{climate_var}_{weights}_3\"] = np.power(climate_val,3) - np.power(prev_climate_val,3)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9042d5b6-692a-4106-a689-e39ea342e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_natural_disasters_to_dataset(dataset, extracted_disasters):\n",
    "    for country, data_by_year in dataset.items():\n",
    "        for year, data in data_by_year.items():\n",
    "            for disaster in disaster_types_to_extract:\n",
    "                if country in extracted_disasters and year in extracted_disasters[country] and disaster in extracted_disasters[country][year]:\n",
    "                    dataset[country][year][disaster] = 1\n",
    "                else:\n",
    "                    dataset[country][year][disaster] = 0\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfef94af-334d-4df1-992f-0263133a5dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Drought': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_disasters[\"AFG\"][1969]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5d414c-683e-4ecc-b91c-4d1dba03426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data = gdp_data.replace(\"..\", np.NaN)\n",
    "formatted_gdp_data = format_target_data(gdp_data, gdp_years, \"year [YRyear]\", \"Country Code\", \"fd_ln_gdp\")\n",
    "formatted_tfp_data = format_target_data(tfp_data, tfp_years, \"year\", \"ISO3\", \"fd_ln_tfp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bde7dbd-c3c5-4a3c-880e-58045ebc635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_disasters = {}\n",
    "missing_countries = set()\n",
    "extreme_temp_subtypes = set()\n",
    "for row in natural_disasters_data.iterrows():\n",
    "    row = row[1]\n",
    "    disaster_type = row[\"Disaster Type\"]\n",
    "    if disaster_type in disaster_types_to_extract:\n",
    "        if disaster_type == \"Extreme temperature\" and row[\"Disaster Subtype\"] != \"Heat wave\":\n",
    "            continue\n",
    "        country = row.ISO\n",
    "        year = int(row[\"DisNo.\"].split(\"-\")[0])\n",
    "        if disaster_type == \"Extreme temperature\":\n",
    "            disaster_type = \"Heat_wave\"\n",
    "        if country not in extracted_disasters:\n",
    "            extracted_disasters[country] = {}\n",
    "        if year not in extracted_disasters[country]:\n",
    "            extracted_disasters[country][year] = {}\n",
    "        extracted_disasters[country][year][disaster_type] = 1\n",
    "\n",
    "formatted_gdp_data = add_natural_disasters_to_dataset(formatted_gdp_data, extracted_disasters)\n",
    "formatted_tfp_data = add_natural_disasters_to_dataset(formatted_tfp_data, extracted_disasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece6d21d-8247-4be6-8330-5b6e57b43dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for climate_var in [\"temp\",\"precip\",\"humidity\"]:\n",
    "    for weights in [\"unweighted\", \"pop_weighted\",\"ag_weighted\"]:\n",
    "        aggregate_var = \"mean\"\n",
    "        if weights != \"unweighted\":\n",
    "            aggregate_var = \"weighted_mean\"\n",
    "        weights_no_dash = weights.replace(\"_\",\"\")\n",
    "        data = pd.read_csv(f\"../data/{climate_var}/monthly/processed_by_country/{weights}/{climate_var}.monthly.bycountry.{weights_no_dash}.mean.csv\")\n",
    "        for row in data.iterrows():\n",
    "            prev_climate_val = None\n",
    "            row = row[1]\n",
    "            country = cc(row.country, origin=\"fips\", destination=\"iso3c\")\n",
    "            if country != None:\n",
    "                for year in range(1960,2024):\n",
    "                    monthly_climate_vals = []\n",
    "                    for month in range(1,13):\n",
    "                        if month < 10:\n",
    "                            month = \"0\" + str(month)\n",
    "                        monthly_climate_vals.append(row[f\"{weights_no_dash}_by_country.{aggregate_var}.X{year}.{month}.01\"])\n",
    "                    annual_climate_mean = np.mean(monthly_climate_vals)\n",
    "                    if climate_var == \"temp\":\n",
    "                        # celsius to kelvin\n",
    "                        annual_climate_mean = annual_climate_mean - 273.15\n",
    "                    elif climate_var == \"precip\":\n",
    "                        # precipitation rate per second to total monthly precipitation (X by approx. # of seconds in a month)\n",
    "                        annual_climate_mean = annual_climate_mean * 2.628e+6\n",
    "                    if year in gdp_years and country in formatted_gdp_data:\n",
    "                        formatted_gdp_data = add_climate_vars_to_dataset(formatted_gdp_data, annual_climate_mean, prev_climate_val, country, year, climate_var, weights)\n",
    "                    if year in tfp_years and country in formatted_tfp_data:\n",
    "                        formatted_tfp_data = add_climate_vars_to_dataset(formatted_tfp_data, annual_climate_mean, prev_climate_val, country, year, climate_var, weights)\n",
    "                    prev_climate_val = annual_climate_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce2a6298-760a-4c89-9aa2-08325f74e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp unweighted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x700248900f70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hayden_freedman/pymc_dev.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m weights_no_dash \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1960\u001b[39m,\u001b[38;5;241m2024\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclimate_var\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/daily/processed_by_country/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mweights\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclimate_var\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.daily.bycountry.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mweights_no_dash\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISO3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cc(data\u001b[38;5;241m.\u001b[39mcountry, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfips\u001b[39m\u001b[38;5;124m\"\u001b[39m, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso3c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     climate_columns \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[:, data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_by_country.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maggregate_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_results = {\"annual_climate_std\":{},\"mean_daily_climate_std\":{}}\n",
    "for climate_var in [\"temp\",\"precip\",\"humidity\"]:\n",
    "    for weights in [\"unweighted\", \"pop_weighted\",\"ag_weighted\"]:\n",
    "        print(climate_var, weights)\n",
    "        aggregate_var = \"mean\"\n",
    "        if weights != \"unweighted\":\n",
    "            aggregate_var = \"weighted_mean\"\n",
    "        weights_no_dash = weights.replace(\"_\",\"\")\n",
    "        for year in range(1960,2024):\n",
    "            data = pd.read_csv(f\"../data/{climate_var}/daily/processed_by_country/{weights}/{climate_var}.daily.bycountry.{weights_no_dash}.{year}.csv\")\n",
    "            data[\"ISO3\"] = cc(data.country, origin=\"fips\", destination=\"iso3c\")\n",
    "            climate_columns = data.loc[:, data.columns.str.startswith(f\"{weights}_by_country.{aggregate_var}\")]\n",
    "            data[\"annual_std\"] = np.std(climate_columns, axis=1)\n",
    "            # TODO: ensure that this number is correct for all files\n",
    "            for measurement in range(0,1464,4):\n",
    "                data[f\"daily_std_{int(measurement/4)}\"] = np.std(climate_columns.iloc[:,measurement:measurement+4], axis=1)\n",
    "            data[\"mean_daily_std\"] = np.mean(data.loc[:, data.columns.str.startswith(\"daily_std\")], axis=1)\n",
    "            for row in data.iterrows():\n",
    "                row = row[1]\n",
    "                country = row.ISO3\n",
    "                mean_daily_climate_std = row.mean_daily_std\n",
    "                annual_climate_std = row.annual_std\n",
    "                prev_daily_std, prev_annual_std = None, None\n",
    "                if country in prev_results[\"mean_daily_climate_std\"] and year-1 in prev_results[\"mean_daily_climate_std\"][country]:\n",
    "                    prev_daily_std = prev_results[\"mean_daily_climate_std\"][country][year-1]\n",
    "                if country in prev_results[\"annual_climate_std\"] and year-1 in prev_results[\"annual_climate_std\"][country]:\n",
    "                    prev_annual_std = prev_results[\"annual_climate_std\"][country][year-1]\n",
    "                if year in gdp_years and country in formatted_gdp_data:\n",
    "                    formatted_gdp_data = add_climate_vars_to_dataset(formatted_gdp_data, mean_daily_climate_std, prev_daily_std, country, year, climate_var + \"_daily_std\", weights)\n",
    "                    formatted_gdp_data = add_climate_vars_to_dataset(formatted_gdp_data, annual_climate_std, prev_annual_std, country, year, climate_var + \"_annual_std\", weights)\n",
    "                if year in tfp_years and country in formatted_tfp_data:\n",
    "                    formatted_tfp_data = add_climate_vars_to_dataset(formatted_tfp_data, mean_daily_climate_std, prev_daily_std, country, year, climate_var + \"_daily_std\", weights)\n",
    "                    formatted_tfp_data = add_climate_vars_to_dataset(formatted_tfp_data, annual_climate_std, prev_annual_std, country, year, climate_var + \"_annual_std\", weights)\n",
    "                if country not in prev_results[\"mean_daily_climate_std\"]:\n",
    "                    prev_results[\"mean_daily_climate_std\"][country] = {}\n",
    "                prev_results[\"mean_daily_climate_std\"][country][year] = mean_daily_climate_std\n",
    "                if country not in prev_results[\"annual_climate_std\"]:\n",
    "                    prev_results[\"annual_climate_std\"][country] = {}\n",
    "                prev_results[\"annual_climate_std\"][country][year] = annual_climate_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f796554c-f0a8-4b8d-aff0-e46af96e29d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFG 1992 temp_daily_std_ag_weighted\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m, in \u001b[0;36mwrite_regression_data_to_file\u001b[0;34m(file, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     new_row\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'temp_daily_std_ag_weighted'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow(new_row)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/regression/gdp_regression_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m gdp_file:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mwrite_regression_data_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdp_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatted_gdp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# with open(\"../data/regression/tfp_regression_data.csv\", \"w\") as tfp_file:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     write_regression_data_to_file(tfp_file, formatted_tfp_data)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[54], line 15\u001b[0m, in \u001b[0;36mwrite_regression_data_to_file\u001b[0;34m(file, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(country, year, column)\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     16\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(new_row)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def write_regression_data_to_file(file, data):\n",
    "    writer = csv.writer(file)\n",
    "    headers =[\"country\",\"year\"]\n",
    "    for column in data[\"AFG\"][1961]:\n",
    "        headers.append(column)\n",
    "    writer.writerow(headers)\n",
    "    for country, data_by_year in data.items():\n",
    "        for year, data in data_by_year.items():\n",
    "            new_row = [country,year]\n",
    "            for column in headers[2:]:\n",
    "                try:\n",
    "                    new_row.append(data[column])\n",
    "                except KeyError:\n",
    "                    print(country, year, column)\n",
    "                    assert 1 == 2\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "with open(\"../data/regression/gdp_regression_data.csv\", \"w\") as gdp_file:\n",
    "    write_regression_data_to_file(gdp_file, formatted_gdp_data)\n",
    "# with open(\"../data/regression/tfp_regression_data.csv\", \"w\") as tfp_file:\n",
    "#     write_regression_data_to_file(tfp_file, formatted_tfp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff22a5-3b49-462b-8cc4-c81f1e03b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"country\":[],\"year\":[],\n",
    "    # outcome variables\n",
    "    \"fd_ln_GDP\":[],\"fd_ln_TFP\":[],\n",
    "    # mean annual temp\n",
    "    \"temp_uw_mean_annual\":[],\"temp2_uw_mean_annual\":[],\"fd_temp_uw_mean_annual\":[],\"fd_temp2_uw_mean_annual\":[],\n",
    "    # mean annual precip\n",
    "    \"precip_uw_mean_annual\":[],\"precip2_uw_mean_annual:[]\",\"fd_precip_uw_mean_annual\":[],\"fd_precip2_uw_mean_annual\":[],\n",
    "    # mean annual humidity\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcd35a99-e462-4e60-a4d5-28a122efb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [\"tmean\",\"tmean_sq\",\"tmean_cu\",\"fd_tmean\",\"fd_tmean_sq\",\"fd_tmean_cu\",\"prcp\",\"prcp_sq\",\"prcp_cu\",\"fd_prcp\",\"fd_prcp_sq\",\"fd_prcp_cu\"]\n",
    "permutation_list = [\n",
    "    np.ones(len(var_list)),\n",
    "    [0,0,0,1,1,0,0,0,0,1,1,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdf2ecf3-a54c-491a-8069-c014b35dae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "for var in var_list:\n",
    "    headers.append(var)\n",
    "headers.append(\"In-sample MSE\")\n",
    "with open(\"test_out.csv\", \"w\") as file_output:\n",
    "    writer = csv.writer(file_output)\n",
    "    writer.writerow(headers)\n",
    "    for permutation in permutation_list:\n",
    "        vars = \" + \".join([var for index, var in enumerate(var_list) if permutation[index] == 1])\n",
    "        regression = pf.feols(f\"fd_log_tfp ~ {vars} | ISO3 + year\", data=data)\n",
    "        yhat = regression.predict()\n",
    "        error = np.mean(np.square(yhat-data.fd_log_tfp))\n",
    "        res_row = []\n",
    "        for i in permutation:\n",
    "            res_row.append(i)\n",
    "        res_row.append(error)\n",
    "        writer.writerow(res_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ba66254-90ad-4ac3-b3d5-7017b849b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>t value</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coefficient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fd_tmean</th>\n",
       "      <td>-6.475999e-03</td>\n",
       "      <td>9.191869e-03</td>\n",
       "      <td>-0.704536</td>\n",
       "      <td>0.482058</td>\n",
       "      <td>-2.462014e-02</td>\n",
       "      <td>1.166814e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd_tmean_sq</th>\n",
       "      <td>-4.752681e-05</td>\n",
       "      <td>2.257485e-04</td>\n",
       "      <td>-0.210530</td>\n",
       "      <td>0.833505</td>\n",
       "      <td>-4.931395e-04</td>\n",
       "      <td>3.980859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd_prcp</th>\n",
       "      <td>1.816850e-04</td>\n",
       "      <td>5.712337e-05</td>\n",
       "      <td>3.180572</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>6.892724e-05</td>\n",
       "      <td>2.944428e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd_prcp_sq</th>\n",
       "      <td>-1.818987e-07</td>\n",
       "      <td>5.850870e-08</td>\n",
       "      <td>-3.108918</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-2.973910e-07</td>\n",
       "      <td>-6.640643e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Estimate    Std. Error   t value  Pr(>|t|)          2.5%  \\\n",
       "Coefficient                                                                 \n",
       "fd_tmean    -6.475999e-03  9.191869e-03 -0.704536  0.482058 -2.462014e-02   \n",
       "fd_tmean_sq -4.752681e-05  2.257485e-04 -0.210530  0.833505 -4.931395e-04   \n",
       "fd_prcp      1.816850e-04  5.712337e-05  3.180572  0.001746  6.892724e-05   \n",
       "fd_prcp_sq  -1.818987e-07  5.850870e-08 -3.108918  0.002200 -2.973910e-07   \n",
       "\n",
       "                    97.5%  \n",
       "Coefficient                \n",
       "fd_tmean     1.166814e-02  \n",
       "fd_tmean_sq  3.980859e-04  \n",
       "fd_prcp      2.944428e-04  \n",
       "fd_prcp_sq  -6.640643e-08  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.tidy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c403e64-f7e4-4b44-800a-cb06b8643853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: fd_log_tfp, Fixed effects: ISO3+year\n",
      "Inference:  CRV1\n",
      "Observations:  9255\n",
      "\n",
      "| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n",
      "|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n",
      "| fd_tmean      |     -0.006 |        0.009 |    -0.705 |      0.482 | -0.025 |   0.012 |\n",
      "| fd_tmean_sq   |     -0.000 |        0.000 |    -0.211 |      0.834 | -0.000 |   0.000 |\n",
      "| fd_prcp       |      0.000 |        0.000 |     3.181 |      0.002 |  0.000 |   0.000 |\n",
      "| fd_prcp_sq    |     -0.000 |        0.000 |    -3.109 |      0.002 | -0.000 |  -0.000 |\n",
      "---\n",
      "RMSE: 0.082 R2: 0.04 R2 Within: 0.01 \n"
     ]
    }
   ],
   "source": [
    "regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0acc4e6d-8477-4b73-b7ac-ddfcb3dfc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_data = pf.estimation.demean(\n",
    "    np.array(data[[\"fd_tmean\", \"fd_tmean_sq\", \"fd_prcp\", \"fd_prcp_sq\"]]), \n",
    "    np.array(data[[\"encoded_iso_id\",\"year\"]]), \n",
    "    np.ones(len(data))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4367dd5c-63d3-46f7-905f-5b0ca0439790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.47599918e-03 -4.75268083e-05  1.81684996e-04 -1.81898741e-07]\n"
     ]
    }
   ],
   "source": [
    "x = centered_data[0]\n",
    "y = np.array(data.fd_log_tfp)\n",
    "model = sm.OLS(y,x)\n",
    "results = model.fit()\n",
    "print(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "787af5f8-11f1-4649-86ba-1412cc68b5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006735429878711787"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict with fixed effects\n",
    "yhat = regression.predict()\n",
    "error = np.square(yhat-data.fd_log_tfp)\n",
    "np.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67169fc3-45af-4fd3-804b-7c0a3d3d0601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006980271648325952"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict without fixed effects\n",
    "yhat_ = results.predict()\n",
    "error = np.square(yhat_-data.fd_log_tfp)\n",
    "np.mean(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
