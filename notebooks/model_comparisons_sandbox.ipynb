{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2819f3-4d33-4f1f-80c3-25bba5845a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"hsoUCG\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.3.3/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"hsoUCG\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"hsoUCG\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"fMKmNI\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.3.3/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"fMKmNI\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"fMKmNI\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pyfixest as pf\n",
    "import statsmodels.api as sm\n",
    "import itertools as it\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5600d6cb-fe76-491b-a1bb-36f1c31d71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: it's probably worth trying models without year fixed effects, as this has the advantage of allowing predictions on unseen years\n",
    "# TODO: MSE should be reduction from an intercept-only model for easier comparison between models\n",
    "# TODO: regarding demeaning, it's not clear whether the global mean should be added back or not (advantages/disadvantages of either approach?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acff22a5-3b49-462b-8cc4-c81f1e03b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data_full = pd.read_csv(\"../data/regression/gdp_regression_data.csv\").dropna().reset_index()\n",
    "regression_data_insample = pd.read_csv(\"../data/regression/gdp_regression_data_insample.csv\")\n",
    "regression_data_outsample = pd.read_csv(\"../data/regression/gdp_regression_data_outsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edc5703d-2027-4cfa-827c-0f6d5aa8a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit()\n",
    "splits = sss.split(regression_data_full[[\"temp_unweighted\",\"temp_unweighted_2\"]], regression_data_full.country + \"_\" + str(regression_data_full.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74f639da-4205-484d-81da-b44410533d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_split, test_split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[1;32m      2\u001b[0m     training_rows \u001b[38;5;241m=\u001b[39m regression_data_full\u001b[38;5;241m.\u001b[39miloc[train_split]\n\u001b[1;32m      3\u001b[0m     test_rows \u001b[38;5;241m=\u001b[39m regression_data_full\u001b[38;5;241m.\u001b[39miloc[test_split]\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:1749\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m \n\u001b[1;32m   1721\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/pymc_dev.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2150\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2148\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2155\u001b[0m     )\n\u001b[1;32m   2157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m   2158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2161\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "for train_split, test_split in splits:\n",
    "    training_rows = regression_data_full.iloc[train_split]\n",
    "    test_rows = regression_data_full.iloc[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b12b9ef-5d32-448e-a5b6-0cca238ee2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(regression_data_full.year))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd35a99-e462-4e60-a4d5-28a122efb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_groups = [\n",
    "    {\n",
    "        \"temp_vars\":[\"temp_unweighted\",\"temp_unweighted_2\",\"temp_unweighted_3\"],\n",
    "        \"precip_vars\":[\"precip_unweighted\",\"precip_unweighted_2\",\"precip_unweighted_3\"],\n",
    "        \"humidity_vars\":[\"humidity_unweighted\",\"humidity_unweighted_2\",\"humidity_unweighted_3\"]\n",
    "    },\n",
    "    # {\n",
    "    #     \"temp_vars\":[\"temp_daily_std_unweighted\",\"temp_daily_std_unweighted_2\",\"temp_daily_std_unweighted_3\"],\n",
    "    #     \"precip_vars\":[\"precip_daily_std_unweighted\",\"precip_daily_std_unweighted_2\",\"precip_daily_std_unweighted_3\"],\n",
    "    #     \"humidity_vars\":[\"humidity_daily_std_unweighted\",\"humidity_daily_std_unweighted_2\",\"humidity_daily_std_unweighted_3\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"temp_vars\":[\"temp_annual_std_unweighted\",\"temp_annual_std_unweighted_2\",\"temp_annual_std_unweighted_3\"],\n",
    "    #     \"precip_vars\":[\"precip_annual_std_unweighted\",\"precip_annual_std_unweighted_2\",\"precip_annual_std_unweighted_3\"],\n",
    "    #     \"humidity_vars\":[\"humidity_annual_std_unweighted\",\"humidity_annual_std_unweighted_2\",\"humidity_annual_std_unweighted_3\"]\n",
    "    # },\n",
    "    {\n",
    "        \"temp_vars\":[\"fd_temp_unweighted\",\"fd_temp_unweighted_2\",\"fd_temp_unweighted_3\"],\n",
    "        \"precip_vars\":[\"fd_precip_unweighted\",\"fd_precip_unweighted_2\",\"fd_precip_unweighted_3\"],\n",
    "        \"humidity_vars\":[\"fd_humidity_unweighted\",\"fd_humidity_unweighted_2\",\"fd_humidity_unweighted_3\"]\n",
    "    },\n",
    "    # {\n",
    "    #     \"temp_vars\":[\"fd_temp_daily_std_unweighted\",\"fd_temp_daily_std_unweighted_2\",\"fd_temp_daily_std_unweighted_3\"],\n",
    "    #     \"precip_vars\":[\"fd_precip_daily_std_unweighted\",\"fd_precip_daily_std_unweighted_2\",\"fd_precip_daily_std_unweighted_3\"],\n",
    "    #     \"humidity_vars\":[\"fd_humidity_daily_std_unweighted\",\"fd_humidity_daily_std_unweighted_2\",\"fd_humidity_daily_std_unweighted_3\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"temp_vars\":[\"fd_temp_annual_std_unweighted\",\"fd_temp_annual_std_unweighted_2\",\"fd_temp_annual_std_unweighted_3\"],\n",
    "    #     \"precip_vars\":[\"fd_precip_annual_std_unweighted\",\"fd_precip_annual_std_unweighted_2\",\"fd_precip_annual_std_unweighted_3\"],\n",
    "    #     \"humidity_vars\":[\"fd_humidity_annual_std_unweighted\",\"fd_humidity_annual_std_unweighted_2\",\"fd_humidity_annual_std_unweighted_3\"]\n",
    "    # }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c88421f-62fc-4c78-8395-9fe2937cffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(results, in_sample_data, out_sample_data, target_var, temp_var_list=None, precip_var_list=None, humidity_var_list=None, fe_string = \"country + year\"):\n",
    "    assert any([temp_var_list, precip_var_list, humidity_var_list]) != None\n",
    "    var_list = []\n",
    "    if temp_var_list != None:\n",
    "        for var in temp_var_list: var_list.append(var)\n",
    "    if precip_var_list != None:\n",
    "        for var in precip_var_list: var_list.append(var)\n",
    "    if humidity_var_list != None:\n",
    "        for var in humidity_var_list: var_list.append(var)\n",
    "    var_string = \" + \".join(var_list)\n",
    "    for incremental_effects in [0,1,2,3]:\n",
    "        for i in range(incremental_effects):\n",
    "            for incremental_col in [col for col in regression_data_insample.columns if col.endswith(f\"incremental_effect_{str(i+1)}\")]:\n",
    "                var_list.append(incremental_col)\n",
    "            var_string += f\"*incremental_effects_{str(i+i)}\"\n",
    "        covariate_string = \" + \".join(var_list)\n",
    "        regression = pf.feols(\n",
    "            f\"{target_var} ~ {covariate_string} | {fe_string}\", \n",
    "            data=in_sample_data\n",
    "        )\n",
    "        # TODO: MSE should be a reduction from an intercept-only model\n",
    "        in_sample_mse = np.mean(np.square(regression.predict()-in_sample_data[target_var]))\n",
    "        out_sample_mse = np.mean(np.square(regression.predict(out_sample_data)-out_sample_data[target_var]))\n",
    "        results[\"covariate_string\"].append(covariate_string)\n",
    "        results[\"in_sample_mse\"].append(in_sample_mse)\n",
    "        results[\"out_sample_mse\"].append(out_sample_mse)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1e187e-f00f-458e-ba32-5d5ef3df30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"covariate_string\":[],\"out_sample_mse\":[],\"in_sample_mse\":[]}\n",
    "for group in model_groups:\n",
    "    temp_vars, precip_vars, humidity_vars = [], [], []\n",
    "    for var in group[\"temp_vars\"]:\n",
    "        temp_vars.append(var)\n",
    "        results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", temp_vars)\n",
    "    for var in group[\"precip_vars\"]:\n",
    "        precip_vars.append(var)\n",
    "        results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", None, precip_vars)\n",
    "    for var in group[\"humidity_vars\"]:\n",
    "        humidity_vars.append(var)\n",
    "        results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", None, None, humidity_vars)\n",
    "    results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", temp_vars, precip_vars)\n",
    "    results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", None, precip_vars, humidity_vars)\n",
    "    results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", temp_vars, None, humidity_vars)\n",
    "    results = run_regression(results, regression_data_insample, regression_data_outsample, \"fd_ln_gdp\", temp_vars, precip_vars, humidity_vars)\n",
    "pd.DataFrame.from_dict(results).sort_values([\"out_sample_mse\",\"in_sample_mse\"]).to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdf2ecf3-a54c-491a-8069-c014b35dae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "for var in var_list:\n",
    "    headers.append(var)\n",
    "headers.append(\"In-sample MSE\")\n",
    "with open(\"test_out.csv\", \"w\") as file_output:\n",
    "    writer = csv.writer(file_output)\n",
    "    writer.writerow(headers)\n",
    "    for permutation in permutation_list:\n",
    "        vars = \" + \".join([var for index, var in enumerate(var_list) if permutation[index] == 1])\n",
    "        regression = pf.feols(f\"fd_log_tfp ~ {vars} | country + year\", data=data)\n",
    "        yhat = regression.predict()\n",
    "        error = np.mean(np.square(yhat-data.fd_log_tfp))\n",
    "        res_row = []\n",
    "        for i in permutation:\n",
    "            res_row.append(i)\n",
    "        res_row.append(error)\n",
    "        writer.writerow(res_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba66254-90ad-4ac3-b3d5-7017b849b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>t value</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coefficient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temp_unweighted</th>\n",
       "      <td>0.014584</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>2.091417</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.028352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_unweighted_2</th>\n",
       "      <td>-0.000984</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>-1.538625</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>-0.002247</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_unweighted_3</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.354382</td>\n",
       "      <td>0.177466</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Estimate  Std. Error   t value  Pr(>|t|)      2.5%  \\\n",
       "Coefficient                                                             \n",
       "temp_unweighted    0.014584    0.006973  2.091417  0.038022  0.000816   \n",
       "temp_unweighted_2 -0.000984    0.000640 -1.538625  0.125811 -0.002247   \n",
       "temp_unweighted_3  0.000021    0.000016  1.354382  0.177466 -0.000010   \n",
       "\n",
       "                      97.5%  \n",
       "Coefficient                  \n",
       "temp_unweighted    0.028352  \n",
       "temp_unweighted_2  0.000279  \n",
       "temp_unweighted_3  0.000053  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.tidy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c403e64-f7e4-4b44-800a-cb06b8643853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: fd_log_tfp, Fixed effects: ISO3+year\n",
      "Inference:  CRV1\n",
      "Observations:  9255\n",
      "\n",
      "| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n",
      "|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n",
      "| fd_tmean      |     -0.006 |        0.009 |    -0.705 |      0.482 | -0.025 |   0.012 |\n",
      "| fd_tmean_sq   |     -0.000 |        0.000 |    -0.211 |      0.834 | -0.000 |   0.000 |\n",
      "| fd_prcp       |      0.000 |        0.000 |     3.181 |      0.002 |  0.000 |   0.000 |\n",
      "| fd_prcp_sq    |     -0.000 |        0.000 |    -3.109 |      0.002 | -0.000 |  -0.000 |\n",
      "---\n",
      "RMSE: 0.082 R2: 0.04 R2 Within: 0.01 \n"
     ]
    }
   ],
   "source": [
    "regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bb539-ffcc-4de5-bcf5-a0d3ec7a5d9e",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0acc4e6d-8477-4b73-b7ac-ddfcb3dfc014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4085/637950435.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  regression_data_full[\"encoded_country\"] = [int(val) for val in enc.transform(np.array(regression_data_full.country).reshape(-1,1))]\n"
     ]
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "ordered_country_list = list(dict.fromkeys(regression_data_full.country))\n",
    "enc.fit(np.array(ordered_country_list).reshape(-1,1))\n",
    "regression_data_full[\"encoded_country\"] = [int(val) for val in enc.transform(np.array(regression_data_full.country).reshape(-1,1))]\n",
    "columns_to_center = [\n",
    "        \"temp_unweighted\",\n",
    "        \"temp_unweighted_2\",\n",
    "        \"temp_unweighted_3\",\n",
    "        \"fd_temp_unweighted\",\n",
    "        \"fd_temp_unweighted_2\",\n",
    "        \"fd_temp_unweighted_3\",\n",
    "        \"precip_unweighted\",\n",
    "        \"precip_unweighted_2\",\n",
    "        \"precip_unweighted_3\",\n",
    "        \"fd_precip_unweighted\",\n",
    "        \"fd_precip_unweighted_2\",\n",
    "        \"fd_precip_unweighted_3\",\n",
    "        \"humidity_unweighted\",\n",
    "        \"humidity_unweighted_2\",\n",
    "        \"humidity_unweighted_3\",\n",
    "        \"fd_humidity_unweighted\",\n",
    "        \"fd_humidity_unweighted_2\",\n",
    "        \"fd_humidity_unweighted_3\"\n",
    "    ]\n",
    "centered_data = pf.estimation.demean(\n",
    "    np.array(regression_data_full[columns_to_center]), \n",
    "    np.array(regression_data_full[[\"encoded_country\",\"year\"]]), \n",
    "    np.ones(len(regression_data_full))\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bfa59f62-74f6-4372-8df7-d83c5a6f5969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4085/1361240033.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_years = np.array(random.sample(set(regression_data_full.year), k=len(set(regression_data_full.year))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "cv_folds = 10\n",
    "sampled_years = np.array(random.sample(set(regression_data_full.year), k=len(set(regression_data_full.year))))\n",
    "year_cut = OrdinalEncoder().fit_transform(np.array(list(pd.cut(range(1,63), bins=cv_folds))).reshape(-1,1)).flatten()\n",
    "for fold in range(cv_folds):\n",
    "    withheld_years = []\n",
    "    for index, cut in enumerate(year_cut):\n",
    "        if cut == fold:\n",
    "            withheld_years.append(sampled_years[index])\n",
    "    withheld_rows = regression_data_full.loc[(regression_data_full.year.isin(withheld_years))]\n",
    "    training_rows = regression_data_full.loc[(regression_data_full.year.isin(withheld_years) == False)]\n",
    "    training_data, withheld_data = [], []\n",
    "    for index, row in enumerate(centered_data):\n",
    "        if index in withheld_rows.index:\n",
    "            withheld_data.append(row)\n",
    "        else:\n",
    "            training_data.append(row)\n",
    "    training_data = np.array(training_data)\n",
    "    withheld_data = np.array(withheld_data)\n",
    "    training_rows = training_rows.reset_index()\n",
    "    withheld_rows = withheld_rows.reset_index()\n",
    "    withheld_data_dict, training_data_dict = {}, {}\n",
    "    for index, column in enumerate(columns_to_center):\n",
    "        withheld_data_dict[column] = withheld_data[:,index]\n",
    "        training_data_dict[column] = training_data[:,index]\n",
    "    training_data = pd.concat([pd.DataFrame.from_dict(training_data_dict), training_rows[[\"fd_ln_gdp\",\"country\",\"year\"]], training_rows.loc[:, training_rows.columns.str.contains(('_incremental_effect'))]], axis=1)\n",
    "    withheld_data = pd.concat([pd.DataFrame.from_dict(withheld_data_dict), withheld_rows[[\"fd_ln_gdp\",\"country\",\"year\"]], withheld_rows.loc[:, withheld_rows.columns.str.contains(('_incremental_effect'))]], axis=1)\n",
    "    training_data.to_csv(f\"../data/regression/cross_validation/gdp_regression_data_train_cv_{fold}.csv\")\n",
    "    withheld_data.to_csv(f\"../data/regression/cross_validation/gdp_regression_data_test_cv_{fold}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c07b0ea-443c-424f-b0ff-024fd091b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_interval_accuracy(x, y, predictions, cov_mat):\n",
    "    results = []\n",
    "    for index, row in enumerate(x.itertuples()):\n",
    "        x_data = list(row[1:])\n",
    "        y_real = y.iloc[index]\n",
    "        se_pred = np.sqrt(np.linalg.multi_dot([x_data, cov_mat, np.transpose(x_data)]))\n",
    "        prediction_interval = (predictions[index]-se_pred*1.9603795, predictions[index]+se_pred*1.9603795)\n",
    "        if y_real >= prediction_interval[0] and y_real <= prediction_interval[1]:\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8852a4-998d-44b7-9e5d-e92e8c049964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression_with_cv(results, num_folds, target_var, temp_var_list=None, precip_var_list=None, humidity_var_list=None, incremental_effects=None, fe_string = \"0\"):\n",
    "    print(temp_var_list, precip_var_list, humidity_var_list, f\"incremental_effects: {incremental_effects}\")\n",
    "    assert any([temp_var_list, precip_var_list, humidity_var_list]) != None\n",
    "    var_list = []\n",
    "    if temp_var_list != None:\n",
    "        for var in temp_var_list: var_list.append(var)\n",
    "    if precip_var_list != None:\n",
    "        for var in precip_var_list: var_list.append(var)\n",
    "    if humidity_var_list != None:\n",
    "        for var in humidity_var_list: var_list.append(var)\n",
    "    if incremental_effects != None:\n",
    "        for i in range(incremental_effects):\n",
    "            for incremental_col in [col for col in regression_data_insample.columns if col.endswith(f\"incremental_effect_{str(i+1)}\")]:\n",
    "                var_list.append(incremental_col)\n",
    "    for fold in range(num_folds):\n",
    "        in_sample_mse, out_sample_mse, in_sample_pred_int_acc, out_sample_pred_int_acc = [], [], [], []\n",
    "        train_data = pd.read_csv(f\"../data/regression/cross_validation/gdp_regression_data_train_cv_{fold}.csv\")\n",
    "        test_data = pd.read_csv(f\"../data/regression/cross_validation/gdp_regression_data_test_cv_{fold}.csv\")\n",
    "        x = train_data[var_list]\n",
    "        x_test = test_data[var_list]\n",
    "        x = sm.add_constant(x)\n",
    "        x_test = sm.add_constant(x_test)\n",
    "        model = sm.OLS(train_data[target_var],x)\n",
    "        regression = model.fit()\n",
    "        in_sample_predictions = regression.predict()\n",
    "        out_sample_predictions = regression.predict(x_test)\n",
    "        # calculate mse\n",
    "        in_sample_mse.append(np.mean(np.square(in_sample_predictions-train_data[target_var])))\n",
    "        out_sample_mse.append(np.mean(np.square(out_sample_predictions-test_data[target_var])))\n",
    "        # calculate prediction interval accuracy\n",
    "        in_sample_pred_int_acc.append(calculate_prediction_interval_accuracy(x, train_data[target_var], in_sample_predictions, regression.cov_params()))\n",
    "        out_sample_pred_int_acc.append(calculate_prediction_interval_accuracy(x_test, test_data[target_var],out_sample_predictions, regression.cov_params()))\n",
    "    results[\"covariate_string\"].append(\",\".join(var_list))\n",
    "    results[\"in_sample_mse\"].append(np.mean(in_sample_mse))\n",
    "    results[\"out_sample_mse\"].append(np.mean(out_sample_mse))\n",
    "    results[\"in_sample_pred_int_acc\"].append(np.mean(in_sample_pred_int_acc))\n",
    "    results[\"out_sample_pred_int_acc\"].append(np.mean(out_sample_pred_int_acc))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12c6471-084a-4c17-a148-b53bbee178ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp_unweighted'] None None incremental_effects: None\n",
      "['temp_unweighted', 'temp_unweighted_2'] None None incremental_effects: None\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None None incremental_effects: None\n",
      "None ['precip_unweighted'] None incremental_effects: None\n",
      "None ['precip_unweighted', 'precip_unweighted_2'] None incremental_effects: None\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: None\n",
      "None None ['humidity_unweighted'] incremental_effects: None\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2'] incremental_effects: None\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: None\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: None\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: None\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: None\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: None\n",
      "['fd_temp_unweighted'] None None incremental_effects: None\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2'] None None incremental_effects: None\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None None incremental_effects: None\n",
      "None ['fd_precip_unweighted'] None incremental_effects: None\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2'] None incremental_effects: None\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: None\n",
      "None None ['fd_humidity_unweighted'] incremental_effects: None\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2'] incremental_effects: None\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: None\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: None\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: None\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: None\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: None\n",
      "['temp_unweighted'] None None incremental_effects: 1\n",
      "['temp_unweighted', 'temp_unweighted_2'] None None incremental_effects: 1\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None None incremental_effects: 1\n",
      "None ['precip_unweighted'] None incremental_effects: 1\n",
      "None ['precip_unweighted', 'precip_unweighted_2'] None incremental_effects: 1\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 1\n",
      "None None ['humidity_unweighted'] incremental_effects: 1\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2'] incremental_effects: 1\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 1\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 1\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 1\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 1\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 1\n",
      "['fd_temp_unweighted'] None None incremental_effects: 1\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2'] None None incremental_effects: 1\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None None incremental_effects: 1\n",
      "None ['fd_precip_unweighted'] None incremental_effects: 1\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2'] None incremental_effects: 1\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 1\n",
      "None None ['fd_humidity_unweighted'] incremental_effects: 1\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2'] incremental_effects: 1\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 1\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 1\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 1\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 1\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 1\n",
      "['temp_unweighted'] None None incremental_effects: 2\n",
      "['temp_unweighted', 'temp_unweighted_2'] None None incremental_effects: 2\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None None incremental_effects: 2\n",
      "None ['precip_unweighted'] None incremental_effects: 2\n",
      "None ['precip_unweighted', 'precip_unweighted_2'] None incremental_effects: 2\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 2\n",
      "None None ['humidity_unweighted'] incremental_effects: 2\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2'] incremental_effects: 2\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 2\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 2\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 2\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 2\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 2\n",
      "['fd_temp_unweighted'] None None incremental_effects: 2\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2'] None None incremental_effects: 2\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None None incremental_effects: 2\n",
      "None ['fd_precip_unweighted'] None incremental_effects: 2\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2'] None incremental_effects: 2\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 2\n",
      "None None ['fd_humidity_unweighted'] incremental_effects: 2\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2'] incremental_effects: 2\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 2\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 2\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 2\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 2\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 2\n",
      "['temp_unweighted'] None None incremental_effects: 3\n",
      "['temp_unweighted', 'temp_unweighted_2'] None None incremental_effects: 3\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None None incremental_effects: 3\n",
      "None ['precip_unweighted'] None incremental_effects: 3\n",
      "None ['precip_unweighted', 'precip_unweighted_2'] None incremental_effects: 3\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 3\n",
      "None None ['humidity_unweighted'] incremental_effects: 3\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2'] incremental_effects: 3\n",
      "None None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 3\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] None incremental_effects: 3\n",
      "None ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 3\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] None ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 3\n",
      "['temp_unweighted', 'temp_unweighted_2', 'temp_unweighted_3'] ['precip_unweighted', 'precip_unweighted_2', 'precip_unweighted_3'] ['humidity_unweighted', 'humidity_unweighted_2', 'humidity_unweighted_3'] incremental_effects: 3\n",
      "['fd_temp_unweighted'] None None incremental_effects: 3\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2'] None None incremental_effects: 3\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None None incremental_effects: 3\n",
      "None ['fd_precip_unweighted'] None incremental_effects: 3\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2'] None incremental_effects: 3\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 3\n",
      "None None ['fd_humidity_unweighted'] incremental_effects: 3\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2'] incremental_effects: 3\n",
      "None None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 3\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] None incremental_effects: 3\n",
      "None ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 3\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] None ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 3\n",
      "['fd_temp_unweighted', 'fd_temp_unweighted_2', 'fd_temp_unweighted_3'] ['fd_precip_unweighted', 'fd_precip_unweighted_2', 'fd_precip_unweighted_3'] ['fd_humidity_unweighted', 'fd_humidity_unweighted_2', 'fd_humidity_unweighted_3'] incremental_effects: 3\n"
     ]
    }
   ],
   "source": [
    "results = {\"covariate_string\":[],\"out_sample_mse\":[],\"in_sample_mse\":[],\"in_sample_pred_int_acc\":[],\"out_sample_pred_int_acc\":[]}\n",
    "for incremental_effects in [None,1,2,3]:\n",
    "    for group in model_groups:\n",
    "        temp_vars, precip_vars, humidity_vars = [], [], []\n",
    "        for var in group[\"temp_vars\"]:\n",
    "            temp_vars.append(var)\n",
    "            results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", temp_vars, None, None, incremental_effects)\n",
    "        for var in group[\"precip_vars\"]:\n",
    "            precip_vars.append(var)\n",
    "            results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", None, precip_vars, None, incremental_effects)\n",
    "        for var in group[\"humidity_vars\"]:\n",
    "            humidity_vars.append(var)\n",
    "            results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", None, None, humidity_vars, incremental_effects)\n",
    "        results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", temp_vars, precip_vars, None, incremental_effects)\n",
    "        results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", None, precip_vars, humidity_vars, incremental_effects)\n",
    "        results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", temp_vars, None, humidity_vars, incremental_effects)\n",
    "        results = run_regression_with_cv(results, 10, \"fd_ln_gdp\", temp_vars, precip_vars, humidity_vars, incremental_effects)\n",
    "pd.DataFrame.from_dict(results).sort_values([\"out_sample_pred_int_acc\",\"out_sample_mse\"]).to_csv(\"test_cv_pred_int.csv\")\n",
    "\n",
    "# results = {\"covariate_string\":[],\"out_sample_mse\":[],\"in_sample_mse\":[],\"in_sample_pred_int_acc\":[],\"out_sample_pred_int_acc\":[]}\n",
    "# results = run_regression_with_cv(\n",
    "#     results, \n",
    "#     1, \n",
    "#     \"fd_ln_gdp\", \n",
    "#     [\"fd_temp_unweighted\",\"fd_temp_unweighted_2\",\"fd_temp_unweighted_3\"],\n",
    "#     [\"fd_precip_unweighted\",\"fd_precip_unweighted_2\",\"fd_precip_unweighted_3\"],\n",
    "#     [\"fd_humidity_unweighted\",\"fd_humidity_unweighted_2\",\"fd_humidity_unweighted_3\"]\n",
    "# )\n",
    "# results = run_regression_with_cv(\n",
    "#     results, \n",
    "#     1, \n",
    "#     \"fd_ln_gdp\", \n",
    "#     [\"temp_unweighted\",\"temp_unweighted_2\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "acf9f57f-dddc-4515-8d19-dcc0b6bda337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f\"../data/regression/cross_validation/gdp_regression_data_train_cv_0.csv\")\n",
    "regression = pf.feols(\n",
    "                \"fd_ln_gdp ~ temp_unweighted + temp_unweighted_2 | 0\", \n",
    "                data=train_data\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60950aa-cbf9-43ea-b4fe-97bdf4301aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdp_from_stata = pd.read_csv(\"../data/regression/cross_validation/cv_0_stdp_stata.csv\")\n",
    "in_sample, lowers, uppers, real_y = [], [], [], []\n",
    "for row in stdp_from_stata.itertuples():\n",
    "    interval = (row.yhat-(row.stdp*1.9603795), row.yhat+(row.stdp*1.9603795))\n",
    "    lowers.append(interval[0])\n",
    "    uppers.append(interval[1])\n",
    "    real_y.append(row.fd_ln_gdp)\n",
    "    if row.fd_ln_gdp >= interval[0] and row.fd_ln_gdp <= interval[1]:\n",
    "        in_sample.append(1)\n",
    "    else:\n",
    "        in_sample.append(0)\n",
    "\n",
    "print(np.mean(in_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4367dd5c-63d3-46f7-905f-5b0ca0439790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f\"../data/regression/cross_validation/gdp_regression_data_train_cv_0.csv\")\n",
    "x = np.array(train_data[[\"temp_unweighted\",\"temp_unweighted_2\"]])\n",
    "x = sm.add_constant(x)\n",
    "y = np.array(train_data.fd_ln_gdp)\n",
    "model = sm.OLS(y,x)\n",
    "results = model.fit()\n",
    "yhat = results.predict()\n",
    "prediction_intervals = []\n",
    "for index, obs in enumerate(x):\n",
    "    se_pred = np.linalg.multi_dot([obs, results.cov_params(), np.transpose(obs)])\n",
    "    prediction_interval = (yhat[index] - se_pred * 1.9603795, yhat[index] + se_pred * 1.9603795)\n",
    "    prediction_intervals.append(prediction_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "47067bca-c8af-4f39-be4e-3b21dd5b387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.95883511e-05]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.cov_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "787af5f8-11f1-4649-86ba-1412cc68b5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006735429878711787"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict with fixed effects\n",
    "yhat = regression.predict()\n",
    "error = np.square(yhat-data.fd_log_tfp)\n",
    "np.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67169fc3-45af-4fd3-804b-7c0a3d3d0601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006980271648325952"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict without fixed effects\n",
    "yhat_ = results.predict()\n",
    "error = np.square(yhat_-data.fd_log_tfp)\n",
    "np.mean(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
